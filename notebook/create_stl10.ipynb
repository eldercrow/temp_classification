{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from shutil import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating biased and duplicated STL-10 dataset\n",
    "To verify my duplication removal algorithm, I create a biased and duplicated STL-10 dataset.\n",
    "For that I use the following steps:\n",
    "\n",
    " 1. Download the dataset (use codes from [torchvision](https://pytorch.org/docs/stable/_modules/torchvision/datasets/stl10.html#STL10)).\n",
    " 2. Save original images as jpegs (I prefer this format).\n",
    " 3. Create duplications for images of a specific class.\n",
    " 4. Save the biased dataset.\n",
    " \n",
    "Duplications are created using random scaling and translation.\n",
    "To mimic slight object motion, we generate a few augmentation parameters and interpolate them when generating images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stl-10 load function from torchvision \n",
    "def __loadfile(root, data_file, labels_file=None):\n",
    "    labels = None\n",
    "    if labels_file:\n",
    "        path_to_labels = os.path.join(root, labels_file)\n",
    "        with open(path_to_labels, 'rb') as f:\n",
    "            labels = np.fromfile(f, dtype=np.uint8) - 1  # 0-based\n",
    "\n",
    "    path_to_data = os.path.join(root, data_file)\n",
    "    with open(path_to_data, 'rb') as f:\n",
    "        # read whole file in uint8 chunks\n",
    "        everything = np.fromfile(f, dtype=np.uint8)\n",
    "        images = np.reshape(everything, (-1, 3, 96, 96))\n",
    "        images = np.transpose(images, (0, 1, 3, 2))\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataset = '/home/hyunjoon/dataset/stl-10/stl10_binary/'\n",
    "path_res = '/home/hyunjoon/dataset/stl-10-images/'\n",
    "if not os.path.exists(path_res):\n",
    "    os.mkdir(path_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original training dataset\n",
    "# parse binary files and same as jpeg images\n",
    "fn_images = 'train_X.bin'\n",
    "fn_labels = 'train_y.bin'\n",
    "images, labels = __loadfile(path_dataset, fn_images, fn_labels)\n",
    "\n",
    "annots = ''\n",
    "for ii, (img, label) in enumerate(zip(images, labels)):\n",
    "    img = np.transpose(img, (1, 2, 0))\n",
    "    fn_img = '{:05d}_{:03d}.jpg'.format(ii, label)\n",
    "    cv2.imwrite(os.path.join(path_res, fn_img), img[:, :, ::-1])\n",
    "    annots += '{} {}\\n'.format(fn_img, label)\n",
    "\n",
    "# save corresponding annotations\n",
    "with open(os.path.join(path_res, 'train.txt'), 'w') as fh:\n",
    "    fh.write(annots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original validation dataset\n",
    "fn_images = 'test_X.bin'\n",
    "fn_labels = 'test_y.bin'\n",
    "images, labels = __loadfile(path_dataset, fn_images, fn_labels)\n",
    "\n",
    "annots = ''\n",
    "for ii, (img, label) in enumerate(zip(images, labels)):\n",
    "    img = np.transpose(img, (1, 2, 0))\n",
    "    fn_img = '{:05d}_{:03d}.jpg'.format(ii+10000, label)\n",
    "    cv2.imwrite(os.path.join(path_res, fn_img), img[:, :, ::-1])\n",
    "    annots += '{} {}\\n'.format(fn_img, label)\n",
    "    \n",
    "# save corresponding annotations\n",
    "with open(os.path.join(path_res, 'validation.txt'), 'w') as fh:\n",
    "    fh.write(annots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function `_create_transforms` generate a set of images by interpolating two sets of augmentation parameters.\n",
    "For instance, if we have an augmentation parameters such as (zoom out, translate to left) and (zoom in, translate to right).\n",
    "Then this function interpolates the two augmentation parameters so that the generated images are smoothly changes from zoomed-out, left-translated to zoomed-in, right-translated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate near-duplicated images by interpolating two sets of transform parameters\n",
    "def _create_transforms(img, scale, aspect, trans, num_frames, mean_bgr):\n",
    "    '''\n",
    "    scale: (scale_begin, scale_end)\n",
    "    trans: ((tx0, ty0), (tx1, ty1))\n",
    "    aspect: (aspect_begin, aspect_end)\n",
    "    num_frames: number of augmented images to create\n",
    "    '''\n",
    "    # interpolation weights\n",
    "    alphas = np.arange(num_frames) / (num_frames - 1.0)\n",
    "    \n",
    "    img_hw = img.shape[:2]\n",
    "\n",
    "    def _compute_roi(ss, asp, tx, ty, img_hw):\n",
    "        # compute a target crop region from translation and scale parameters\n",
    "        sx = ss * np.sqrt(asp)\n",
    "        sy = ss / np.sqrt(asp)\n",
    "        \n",
    "        ww = img_hw[1] / sx\n",
    "        hh = img_hw[0] / sy\n",
    "\n",
    "        x0 = tx + (img_hw[1] - ww)\n",
    "        y0 = ty + (img_hw[0] - hh)\n",
    "        #\n",
    "        return [x0, y0, x0+ww, y0+hh]\n",
    "    \n",
    "    def _create_transform(roi, img_hw, mean_bgr):\n",
    "        # create a transform function based on the crop region\n",
    "        a = (img_hw[1]) / (roi[2] - roi[0])\n",
    "        b = (img_hw[0]) / (roi[3] - roi[1])\n",
    "        c = -a * (roi[0] - 0.0)\n",
    "        d = -b * (roi[1] - 0.0)\n",
    "        mapping = np.array([[a, 0, c],\n",
    "                            [0, b, d]]).astype(np.float)\n",
    "        func = lambda x: cv2.warpAffine(x, mapping,\n",
    "                                        (img_hw[1], img_hw[0]),\n",
    "                                        borderMode=cv2.BORDER_REPLICATE)\n",
    "        return func, mapping\n",
    "    \n",
    "    # linearly interpolate the two augmentation parameters,\n",
    "    # and generate augmented images from each interpolated parameter set\n",
    "    r_imgs = []\n",
    "    for ii, a1 in enumerate(alphas):\n",
    "        a0 = 1.0 - a1\n",
    "        ss = scale[0] * a0 + scale[1] * a1\n",
    "        asp = aspect[0] * a0 + aspect[1] * a1\n",
    "        tx = trans[0][0] * a0 + trans[1][0] * a1\n",
    "        ty = trans[0][1] * a0 + trans[1][1] * a1\n",
    "\n",
    "        roi = _compute_roi(ss, asp, tx, ty, img_hw)\n",
    "        trans_func, mapping = _create_transform(roi, img_hw, mean_bgr)\n",
    "#         if ii == 0 or ii == len(alphas)-1:\n",
    "#             print('{}: {}'.format(ii, mapping))\n",
    "        \n",
    "        r_imgs.append(trans_func(img))\n",
    "\n",
    "    return r_imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function utilize the above `_create_transformed` to generate a set of images by interpolating multiple augmentation parameters.\n",
    "Assume that we have $k$ sets of augmentation parameters, $(A_0, A_1, \\ldots, A_{k-1})$, \n",
    "we generate image by interpolating $(A_0, A_1), (A_1, A_2), \\ldots (A_{k-1}, A_0)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image(img, scale_range, asp_range, trans_range, num_aug=5, num_frame=20):\n",
    "    '''\n",
    "    '''\n",
    "    # generate a set of random augmentation parameters\n",
    "    p_scale = np.random.uniform(scale_range[0], scale_range[1], num_aug)\n",
    "    p_asp = np.random.uniform(asp_range[0], asp_range[1], num_aug)\n",
    "    p_tx = np.random.uniform(trans_range[0][0], trans_range[0][1], num_aug)\n",
    "    p_ty = np.random.uniform(trans_range[1][0], trans_range[1][1], num_aug)\n",
    "    p_trans = np.stack([p_tx, p_ty], axis=1)\n",
    "      \n",
    "    r_imgs = []\n",
    "    for ii in range(num_aug):\n",
    "        scale = (p_scale[ii], p_scale[(ii+1) % num_aug])\n",
    "        asp = (p_asp[ii], p_asp[(ii+1) % num_aug])\n",
    "        trans = (p_trans[ii], p_trans[(ii+1) % num_aug])\n",
    "        \n",
    "        r_imgs.extend(_create_transforms(img, scale, asp, trans, num_frame, [127, 127, 127]))\n",
    "    \n",
    "    return r_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmentation hyperparameters\n",
    "scale_range = (0.8, 1.25)\n",
    "asp_range = (0.8, 1.25)\n",
    "trans_range = ((-8, 8), (-8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augment training dataset\n",
    "path_dataset = '/home/hyunjoon/dataset/stl-10-images/'\n",
    "path_res = '/home/hyunjoon/dataset/stl-10-biased/'\n",
    "if not os.path.exists(path_res):\n",
    "    os.mkdir(path_res)\n",
    "\n",
    "# read the original annotation that will be augmented\n",
    "with open(os.path.join(path_dataset, 'train.txt'), 'r') as fh:\n",
    "    annots = fh.read().splitlines()\n",
    "annots = [a.split(' ') for a in annots]\n",
    "annots = [(a[0], int(a[1])) for a in annots]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0\n",
    "annot_str = ''\n",
    "for fn, cid in annots:\n",
    "    img = cv2.imread(os.path.join(path_dataset, fn))\n",
    "    \n",
    "    # create duplicated images for the class 0\n",
    "    # the dataset will be biased to the class 0\n",
    "    if cid == 0:\n",
    "        r_imgs = augment_image(img, scale_range, asp_range, trans_range)\n",
    "        for r_img in r_imgs:\n",
    "            dst = os.path.join(path_res, '{:05d}_{:03d}.jpg'.format(k, cid))\n",
    "            cv2.imwrite(dst, r_img)\n",
    "            annot_str += '{:05d}_{:03d}.jpg {}\\n'.format(k, cid, cid)\n",
    "            k += 1\n",
    "\n",
    "    src = os.path.join(path_dataset, fn)\n",
    "    dst = os.path.join(path_res, '{:05d}_{:03d}.jpg'.format(k, cid))\n",
    "    copy(src, dst)\n",
    "    annot_str += '{:05d}_{:03d}.jpg {}\\n'.format(k, cid, cid)\n",
    "    k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(path_res, 'train.txt'), 'w') as fh:\n",
    "    fh.write(annot_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
