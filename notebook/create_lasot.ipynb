{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import glob\n",
    "import random\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataset = '/home/hyunjoon/dataset/lasot/crop/'\n",
    "# classes = os.listdir(path_dataset)\n",
    "classes = ['airplane', 'bicycle', 'boat', 'car', 'cat', 'dog', 'horse', 'motorcycle', 'train', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_train = 'train_lasot_10class.txt'\n",
    "fn_val = 'val_lasot_10class.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28565: airplane\n",
      "13364: bicycle\n",
      "16568: boat\n",
      "17981: car\n",
      "16005: cat\n",
      "12806: dog\n",
      "18284: horse\n",
      "14416: motorcycle\n",
      "15482: train\n",
      "23924: truck\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "177395"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = 0\n",
    "for cname in classes:\n",
    "    N = len(glob.glob(os.path.join(path_dataset, cname) + '/**/*.jpg'))\n",
    "    if N > 0:\n",
    "        print('{}: {}'.format(N, cname))\n",
    "    total += N\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh_train = open(fn_train, 'w')\n",
    "fh_val = open(fn_val, 'w')\n",
    "\n",
    "for cid, cname in enumerate(classes):\n",
    "    dirs = os.listdir(os.path.join(path_dataset, cname))\n",
    "    train_dirs = dirs[:]\n",
    "#     val_dirs = dirs[15:]\n",
    "\n",
    "    for tdir in train_dirs:\n",
    "        fn_list = glob.glob(os.path.join(path_dataset, cname, tdir) + '/*.jpg')\n",
    "        fn_list = np.sort(fn_list)\n",
    "        p7 = int(len(fn_list) * 0.7)\n",
    "        p8 = int(len(fn_list) * 0.85)\n",
    "        \n",
    "        if cname in ('airplane', 'truck'):\n",
    "            train_list = fn_list[:p7]\n",
    "        else:\n",
    "            train_list = fn_list[:p7:20]\n",
    "        annot_str = '\\n'.join(['{} {}'.format(fn.replace(path_dataset, ''), cid) for fn in train_list])\n",
    "        fh_train.write(annot_str)\n",
    "        fh_train.write('\\n')\n",
    "        \n",
    "        val_list = fn_list[p8::10]\n",
    "        annot_str = '\\n'.join(['{} {}'.format(fn.replace(path_dataset, ''), cid) for fn in val_list])\n",
    "        fh_val.write(annot_str)\n",
    "        fh_val.write('\\n')\n",
    "            \n",
    "#     for vdir in val_dirs:\n",
    "#         fn_list = np.array(glob.glob(os.path.join(path_dataset, cname, vdir) + '/*.jpg'))\n",
    "#         fn_list = np.sort(fn_list)\n",
    "#         selected = np.unique(np.around(np.arange(50) / 49.0 * (len(fn_list)-1)).astype(int))\n",
    "# #         random.shuffle(fn_list)\n",
    "#         fn_list = fn_list[selected]\n",
    "#         annot_str = '\\n'.join(['{} {}'.format(fn.replace(path_dataset, ''), cid) for fn in fn_list])\n",
    "#         fh_val.write(annot_str)\n",
    "#         fh_val.write('\\n')\n",
    "            \n",
    "fh_train.close()\n",
    "fh_val.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41155"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_list = open(fn_train).read().splitlines()\n",
    "train_list = [os.path.join(path_dataset, l.split(' ')[0]) for l in train_list]\n",
    "len(train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_filtered = 'train_lasot_10class_filtered.txt'\n",
    "# fn_val = 'val_lasot_10class_filtered.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_feature(img):\n",
    "    if img.dtype == 'uint8':\n",
    "        img = img.astype(float) / 255.0\n",
    "    else:\n",
    "        img = img.astype(float)\n",
    "    r_img = cv2.resize(img, (8, 8), interpolation=cv2.INTER_AREA)\n",
    "    r2 = cv2.resize(img**2, (8, 8), interpolation=cv2.INTER_AREA)\n",
    "    r2 -= r_img**2\n",
    "    r2 = np.sqrt(np.maximum(r2, 0))\n",
    "    r_img = np.concatenate([r_img, 1.0 - r_img, r2, 1.0 - r2], axis=2).ravel()\n",
    "    r_img = r_img / np.sqrt(np.sum(r_img**2))\n",
    "    return r_img\n",
    "\n",
    "\n",
    "def remove_duplication(fn_list):\n",
    "    '''\n",
    "    Args:\n",
    "        fn_list: list of image filenames.\n",
    "\n",
    "    Returns:\n",
    "        filtered_list: list of filenames duplication removed.\n",
    "    '''\n",
    "    all_clr = [color_feature(cv2.imread(fn)) for fn in fn_list]\n",
    "\n",
    "    N = len(fn_list)\n",
    "\n",
    "    fidx = np.random.permutation(np.arange(N))\n",
    "    # hogs = np.array(all_hog)[fidx]\n",
    "    clrs = np.array(all_clr)\n",
    "    kept = []\n",
    "    remaining = fidx.copy()\n",
    "\n",
    "    for ii in range(N):\n",
    "        if len(remaining) == 0:\n",
    "            break\n",
    "        pidx = remaining[0]\n",
    "        kept.append(pidx)\n",
    "        if len(remaining) == 1:\n",
    "            break\n",
    "        \n",
    "        p_clr = clrs[pidx]\n",
    "        sims_clr = np.dot(clrs[remaining], p_clr) ** 100 #np.sum(clrs[remaining] * np.reshape(p_clr, (1, -1)), axis=1)**100\n",
    "        \n",
    "    #     p_hog = hogs[pidx]\n",
    "    #     sims_hog = np.sum(hogs[remaining] * np.reshape(p_hog, (1, -1)), axis=1) / 36\n",
    "        \n",
    "        ridx = np.where((sims_clr) < 0.6)[0]\n",
    "        remaining = remaining[ridx]\n",
    "        \n",
    "        if ii % 1000 == 0:\n",
    "            print(ii)\n",
    "\n",
    "    return [fn_list[idx] for idx in kept]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "filtered_list = remove_duplication(train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(fn_filtered, 'w') as fh:\n",
    "    for line in filtered_list:\n",
    "        fn = line.replace(path_dataset, '')\n",
    "        cid = classes.index(fn.split('/')[0])\n",
    "        fh.write('{} {}\\n'.format(fn, cid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19984, 476, 587, 637, 566, 457, 649, 512, 553, 16734]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perclass = [0 for _ in classes]\n",
    "\n",
    "train_list = open(fn_train).read().splitlines()\n",
    "for l in train_list:\n",
    "    perclass[int(l.split(' ')[1])] += 1\n",
    "\n",
    "perclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[891, 412, 254, 439, 232, 318, 453, 441, 320, 1554]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perclass = [0 for _ in classes]\n",
    "\n",
    "train_list = open(fn_filtered).read().splitlines()\n",
    "for l in train_list:\n",
    "    perclass[int(l.split(' ')[1])] += 1\n",
    "\n",
    "perclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4243"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filtered_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-70afa1769555>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'filtered_list' is not defined"
     ]
    }
   ],
   "source": [
    "len(filtered_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
