{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from shutil import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    " def __loadfile(root, data_file, labels_file=None):\n",
    "    labels = None\n",
    "    if labels_file:\n",
    "        path_to_labels = os.path.join(root, labels_file)\n",
    "        with open(path_to_labels, 'rb') as f:\n",
    "            labels = np.fromfile(f, dtype=np.uint8) - 1  # 0-based\n",
    "\n",
    "    path_to_data = os.path.join(root, data_file)\n",
    "    with open(path_to_data, 'rb') as f:\n",
    "        # read whole file in uint8 chunks\n",
    "        everything = np.fromfile(f, dtype=np.uint8)\n",
    "        images = np.reshape(everything, (-1, 3, 96, 96))\n",
    "        images = np.transpose(images, (0, 1, 3, 2))\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataset = '/home/hyunjoon/dataset/stl-10/stl10_binary/'\n",
    "path_res = '/home/hyunjoon/dataset/stl-10-images/'\n",
    "if not os.path.exists(path_res):\n",
    "    os.mkdir(path_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training dataset\n",
    "fn_images = 'train_X.bin'\n",
    "fn_labels = 'train_y.bin'\n",
    "images, labels = __loadfile(path_dataset, fn_images, fn_labels)\n",
    "\n",
    "annots = ''\n",
    "for ii, (img, label) in enumerate(zip(images, labels)):\n",
    "    img = np.transpose(img, (1, 2, 0))\n",
    "    fn_img = '{:05d}_{:03d}.jpg'.format(ii, label)\n",
    "    cv2.imwrite(os.path.join(path_res, fn_img), img[:, :, ::-1])\n",
    "    annots += '{} {}\\n'.format(fn_img, label)\n",
    "\n",
    "with open(os.path.join(path_res, 'train.txt'), 'w') as fh:\n",
    "    fh.write(annots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation dataset\n",
    "fn_images = 'test_X.bin'\n",
    "fn_labels = 'test_y.bin'\n",
    "images, labels = __loadfile(path_dataset, fn_images, fn_labels)\n",
    "\n",
    "annots = ''\n",
    "for ii, (img, label) in enumerate(zip(images, labels)):\n",
    "    img = np.transpose(img, (1, 2, 0))\n",
    "    fn_img = '{:05d}_{:03d}.jpg'.format(ii+10000, label)\n",
    "    cv2.imwrite(os.path.join(path_res, fn_img), img[:, :, ::-1])\n",
    "    annots += '{} {}\\n'.format(fn_img, label)\n",
    "    \n",
    "with open(os.path.join(path_res, 'validation.txt'), 'w') as fh:\n",
    "    fh.write(annots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_transforms(img, scale, aspect, trans, num_frames, mean_bgr):\n",
    "    '''\n",
    "    scale: (scale_begin, scale_end)\n",
    "    trans: ((tx0, ty0), (tx1, ty1))\n",
    "    aspect: (aspect_begin, aspect_end)\n",
    "    num_frames: number of augmented images to create\n",
    "    '''\n",
    "    # interpolation weights\n",
    "    alphas = np.arange(num_frames) / (num_frames - 1.0)\n",
    "    \n",
    "    img_hw = img.shape[:2]\n",
    "\n",
    "    def _compute_roi(ss, asp, tx, ty, img_hw):\n",
    "        sx = ss * np.sqrt(asp)\n",
    "        sy = ss / np.sqrt(asp)\n",
    "        \n",
    "        ww = img_hw[1] / sx\n",
    "        hh = img_hw[0] / sy\n",
    "\n",
    "        x0 = tx + (img_hw[1] - ww)\n",
    "        y0 = ty + (img_hw[0] - hh)\n",
    "        #\n",
    "        return [x0, y0, x0+ww, y0+hh]\n",
    "    \n",
    "    def _create_transform(roi, img_hw, mean_bgr):\n",
    "        a = (img_hw[1]) / (roi[2] - roi[0])\n",
    "        b = (img_hw[0]) / (roi[3] - roi[1])\n",
    "        c = -a * (roi[0] - 0.0)\n",
    "        d = -b * (roi[1] - 0.0)\n",
    "        mapping = np.array([[a, 0, c],\n",
    "                            [0, b, d]]).astype(np.float)\n",
    "        func = lambda x: cv2.warpAffine(x, mapping,\n",
    "                                        (img_hw[1], img_hw[0]),\n",
    "                                        borderMode=cv2.BORDER_REPLICATE) #,\n",
    "#                                         borderValue=mean_bgr)\n",
    "        return func, mapping\n",
    "    \n",
    "    r_imgs = []\n",
    "    for ii, a1 in enumerate(alphas):\n",
    "        a0 = 1.0 - a1\n",
    "        ss = scale[0] * a0 + scale[1] * a1\n",
    "        asp = aspect[0] * a0 + aspect[1] * a1\n",
    "        tx = trans[0][0] * a0 + trans[1][0] * a1\n",
    "        ty = trans[0][1] * a0 + trans[1][1] * a1\n",
    "\n",
    "        roi = _compute_roi(ss, asp, tx, ty, img_hw)\n",
    "        trans_func, mapping = _create_transform(roi, img_hw, mean_bgr)\n",
    "#         if ii == 0 or ii == len(alphas)-1:\n",
    "#             print('{}: {}'.format(ii, mapping))\n",
    "        \n",
    "        r_imgs.append(trans_func(img))\n",
    "\n",
    "    return r_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image(img, scale_range, asp_range, trans_range, num_aug=5, num_frame=20):\n",
    "    '''\n",
    "    '''\n",
    "    p_scale = np.random.uniform(scale_range[0], scale_range[1], num_aug)\n",
    "    p_asp = np.random.uniform(asp_range[0], asp_range[1], num_aug)\n",
    "    p_tx = np.random.uniform(trans_range[0][0], trans_range[0][1], num_aug)\n",
    "    p_ty = np.random.uniform(trans_range[1][0], trans_range[1][1], num_aug)\n",
    "    p_trans = np.stack([p_tx, p_ty], axis=1)\n",
    "      \n",
    "    r_imgs = []\n",
    "    for ii in range(num_aug):\n",
    "        scale = (p_scale[ii], p_scale[(ii+1) % num_aug])\n",
    "        asp = (p_asp[ii], p_asp[(ii+1) % num_aug])\n",
    "        trans = (p_trans[ii], p_trans[(ii+1) % num_aug])\n",
    "        \n",
    "        r_imgs.extend(create_transforms(img, scale, asp, trans, num_frame, [127, 127, 127]))\n",
    "    \n",
    "    return r_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_range = (0.8, 1.25)\n",
    "asp_range = (0.8, 1.25)\n",
    "trans_range = ((-8, 8), (-8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augment training dataset\n",
    "path_dataset = '/home/hyunjoon/dataset/stl-10-images/'\n",
    "path_res = '/home/hyunjoon/dataset/stl-10-biased/'\n",
    "if not os.path.exists(path_res):\n",
    "    os.mkdir(path_res)\n",
    "\n",
    "with open(os.path.join(path_dataset, 'train.txt'), 'r') as fh:\n",
    "    annots = fh.read().splitlines()\n",
    "annots = [a.split(' ') for a in annots]\n",
    "annots = [(a[0], int(a[1])) for a in annots]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0\n",
    "annot_str = ''\n",
    "for fn, cid in annots:\n",
    "    img = cv2.imread(os.path.join(path_dataset, fn))\n",
    "    if cid == 0:\n",
    "        r_imgs = augment_image(img, scale_range, asp_range, trans_range)\n",
    "        for r_img in r_imgs:\n",
    "            dst = os.path.join(path_res, '{:05d}_{:03d}.jpg'.format(k, cid))\n",
    "            cv2.imwrite(dst, r_img)\n",
    "            annot_str += '{:05d}_{:03d}.jpg {}\\n'.format(k, cid, cid)\n",
    "            k += 1\n",
    "\n",
    "    src = os.path.join(path_dataset, fn)\n",
    "    dst = os.path.join(path_res, '{:05d}_{:03d}.jpg'.format(k, cid))\n",
    "    copy(src, dst)\n",
    "    annot_str += '{:05d}_{:03d}.jpg {}\\n'.format(k, cid, cid)\n",
    "    k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(path_res, 'train.txt'), 'w') as fh:\n",
    "    fh.write(annot_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
