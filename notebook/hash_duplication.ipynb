{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.linalg import orth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supported dataset names: 'cifar10', 'lasot', 'stl10'\n",
    "dataset_name = 'cifar10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "if dataset_name == 'lasot':\n",
    "    path_dataset = '/home/hyunjoon/dataset/lasot/crop/'\n",
    "    list_fn = open(os.path.join(path_dataset, 'train_lasot_10class.txt')).read().splitlines()\n",
    "    list_fn = [l.split(' ') for l in list_fn]\n",
    "    dict_fn = {l[0]: int(l[1]) for l in list_fn}\n",
    "    list_fn = [k for k in dict_fn]\n",
    "    list_label = [v for v in dict_fn.values()]\n",
    "    \n",
    "if dataset_name == 'stl10':\n",
    "    path_dataset = '/home/hyunjoon/dataset/stl-10-biased'\n",
    "    list_fn = np.sort([l for l in os.listdir(path_dataset) if l.endswith('.jpg')])\n",
    "    list_label = [int(os.path.splitext(fn)[0].split('_')[-1]) for fn in list_fn]\n",
    "    \n",
    "if dataset_name == 'cifar10':\n",
    "    path_dataset = '/home/hyunjoon/dataset/cifar-10-biased'\n",
    "    list_fn = np.sort([l for l in os.listdir(path_dataset) if l.endswith('.jpg')])\n",
    "    list_label = [int(os.path.splitext(fn)[0].split('_')[-1]) for fn in list_fn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54500"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total number of images in the dataset\n",
    "len(list_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_imgs = [cv2.resize(cv2.imread(os.path.join(path_dataset, fn)), (32, 32)) for fn in list_fn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def color_feature(img, out_wh=(8, 8)):\n",
    "#     if img.dtype == 'uint8':\n",
    "#         img = img.astype(float) / 255.0\n",
    "#     else:\n",
    "#         img = img.astype(float)\n",
    "#     r_img = cv2.resize(img, out_wh, interpolation=cv2.INTER_AREA)\n",
    "#     r2 = cv2.resize(img**2, out_wh, interpolation=cv2.INTER_AREA)\n",
    "#     r2 -= r_img**2\n",
    "#     r2 = np.sqrt(np.maximum(r2, 0))\n",
    "#     r_img = np.concatenate([r_img, 1.0 - r_img], axis=-1).ravel()\n",
    "#     r2 = np.concatenate([r2, 1.0 - r2], axis=-1).ravel()\n",
    "# #     r_img = np.hstack([r_img, r2])\n",
    "#     r_img = np.hstack([r_img - 0.5, r2 - 0.2])\n",
    "#     r_img = r_img / np.sqrt(np.sum(r_img**2))\n",
    "#     return r_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image feature\n",
    "We use a simple color based image feature - mean and variance of pixel colors within a block.\n",
    "A simple trick is that we use gradient of features to make them zero-meaned ones.\n",
    "We found that this works better with random projection in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cgrad_feature(img, out_wh=(8, 8)):\n",
    "    if img.dtype == 'uint8':\n",
    "        img = img.astype(float) / 255.0\n",
    "    else:\n",
    "        img = img.astype(float)\n",
    "        \n",
    "    r_img = cv2.resize(img, out_wh, interpolation=cv2.INTER_AREA)\n",
    "    r2 = cv2.resize(img**2, out_wh, interpolation=cv2.INTER_AREA)\n",
    "#     r_img = np.mean(r_img, axis=-1, keepdims=True)\n",
    "#     r2 = np.mean(r2, axis=-1, keepdims=True)\n",
    "    r2 -= r_img**2\n",
    "    r2 = np.sqrt(np.maximum(r2, 0))\n",
    "    \n",
    "    # mean and variance feature, zero padding for gradient computation\n",
    "    rr = np.pad(np.concatenate([r_img, r2]), ((1, 1), (1, 1), (0, 0)))\n",
    "\n",
    "    # compute gradients along x- and y-axes\n",
    "    rx = rr[1:-1, :-2, :] - rr[1:-1, 2:, :]\n",
    "    ry = rr[:-2, 1:-1, :] - rr[2:, 1:-1, :]\n",
    "\n",
    "    # concat and l2 normalize\n",
    "    res = np.concatenate([rx, ry], axis=-1)\n",
    "    res = res / np.sqrt(np.sum(res**2))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_clr = np.array([cgrad_feature(img, out_wh=(4, 4)) for img in all_imgs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hashing with random projection \n",
    "[Random projection](https://lovit.github.io/machine%20learning/vector%20indexing/2018/03/28/lsh/) is a widely used technique for hashing features in a [locally sensitive way](https://en.wikipedia.org/wiki/Locality-sensitive_hashing).\n",
    "There are various ways for computing hash-able features after random projection, and we use a simple heuristic; binarize based on signs of random projection results.\n",
    "\n",
    "With hash, we can get $O(kn)$ theoretical complexity, where $k$ is the number of random projection vectors (32 in this experiment).\n",
    "The actual expected complexity would be $\\alpha kn$, where $\\alpha$ represent the average hash collision count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomProjector(object):\n",
    "    '''\n",
    "    '''\n",
    "    def __init__(self, odim=32):\n",
    "        self.odim = odim\n",
    "        self.proj = None\n",
    "\n",
    "    def project(self, feat):\n",
    "        ndim = feat.shape[-1]\n",
    "        feat = np.reshape(feat, (-1, ndim))\n",
    "        \n",
    "        # random projection matrix would become unstable, so reject such cases\n",
    "        assert ndim >= self.odim, '{} is smaller than odim ({})'.format(ndim, self.odim)\n",
    "        \n",
    "        # compute the random projection matrix\n",
    "        if self.proj is None:\n",
    "            for _ in range(100):\n",
    "                # try to get an orthonormal projection matrix\n",
    "                self.proj = orth(np.random.uniform(-1, 1, (ndim, ndim)))[:, :self.odim]\n",
    "                if self.proj.shape[1] == self.odim:\n",
    "                    break\n",
    "            else:\n",
    "                # if failed to get an orthonormal one, just use a random one instead\n",
    "                self.proj = np.random.uniform(-1, 1, (ndim, ndim))\n",
    "                self.proj /= np.sqrt(np.sum(self.proj**2, axis=1, keepdims=True))\n",
    "        \n",
    "        # simple binarization\n",
    "        # compute dot product between each feature and each projection basis,\n",
    "        # then use its sign for the binarization\n",
    "        feat_binary = np.dot(feat, self.proj) >= 0\n",
    "\n",
    "        # generate hash key strings\n",
    "        # assign hex string from each consecutive 16 bits and concatenate\n",
    "        all_key = np.packbits(feat_binary, axis=-1)\n",
    "        all_key = np.array(list(map(lambda row: ''.join(['{:02x}'.format(r) for r in row]), all_key)))\n",
    "        \n",
    "        if len(all_key) == 1:\n",
    "            return all_key[0]\n",
    "        else:\n",
    "            return all_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_img = len(all_clr)\n",
    "projector = RandomProjector(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute hash keys from all the features\n",
    "all_clr = np.reshape(all_clr, (n_img, -1))\n",
    "all_key = projector.project(all_clr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplication using hash\n",
    "clr_dict = {}\n",
    "kept_hash = []\n",
    "\n",
    "# count the number of dot products\n",
    "dot_count = 0\n",
    "\n",
    "fidx = np.random.permutation(np.arange(n_img))\n",
    "for ii in fidx:\n",
    "    key = all_key[ii]\n",
    "    clr = all_clr[ii]\n",
    "    if key not in clr_dict:\n",
    "        clr_dict[key] = [clr]\n",
    "        kept_hash.append(ii)\n",
    "        continue\n",
    "    \n",
    "    # hash collision: compare dot-product based feature similarity\n",
    "    max_sim = np.max(np.dot(clr_dict[key], clr)**50)\n",
    "    \n",
    "    # increase the number of dot product count\n",
    "    dot_count += len(clr_dict[key])\n",
    "    \n",
    "    # keep if not a duplicated one\n",
    "    if max_sim < 0.5:\n",
    "        clr_dict[key].append(clr)\n",
    "        kept_hash.append(ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.8711376146789"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average number of dot product (collision) counts\n",
    "dot_count / n_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12850"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kept_fn = [list_fn[ii] for ii in kept_hash]\n",
    "kept_label = [list_label[ii] for ii in kept_hash]\n",
    "\n",
    "# total number of images after removal\n",
    "len(kept_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8368,  498,  492,  499,  499,  499,  500,  500,  495,  500],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the list after duplication removal\n",
    "classes = np.zeros((10), dtype=np.int32)\n",
    "with open('train_kept_{}_hash.txt'.format(dataset_name), 'w') as fh:\n",
    "    for fn, cid in zip(kept_fn, kept_label):\n",
    "        classes[cid] += 1\n",
    "        fh.write('{} {}\\n'.format(fn, cid))\n",
    "        \n",
    "# see how many images are kept, per-class, after the duplication removal\n",
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline duplication removal\n",
    "This is the baseline method, with $O(n^2)$ complexity.\n",
    "We use NMS to remove duplication in a sequential way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_idx = []\n",
    "fidx = np.random.permutation(np.arange(len(all_clr)))\n",
    "clrs = np.reshape(np.array(all_clr), (len(all_imgs), -1))\n",
    "kept_naive = []\n",
    "remaining = fidx.copy()\n",
    "\n",
    "# count the number of dot products\n",
    "dot_count = 0\n",
    "\n",
    "collapse = {}\n",
    "for ii in range(len(all_clr)):\n",
    "    if len(remaining) == 0:\n",
    "        break\n",
    "    pidx = remaining[0]\n",
    "    kept_naive.append(pidx)\n",
    "    if len(remaining) == 1:\n",
    "        break\n",
    "    \n",
    "    p_clr = clrs[pidx]\n",
    "    \n",
    "    # dot product between a pivot feature and all the remaining ones\n",
    "    sims_clr = np.dot(clrs[remaining], p_clr)**50\n",
    "    ridx = np.where(sims_clr < 0.5)[0]\n",
    "    \n",
    "    # increase the number of dot product counts\n",
    "    dot_count += len(remaining)\n",
    "    \n",
    "    remaining = remaining[ridx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1475.4708440366971"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average number of dot product counts\n",
    "dot_count / n_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7488"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kept_fn = [list_fn[ii] for ii in kept_naive]\n",
    "kept_label = [list_label[ii] for ii in kept_naive]\n",
    "\n",
    "# total number of images after removal\n",
    "len(kept_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3031,  494,  483,  499,  496,  497,  499,  499,  490,  500],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = np.zeros((10), dtype=np.int32)\n",
    "with open('train_kept_{}_naive.txt'.format(dataset_name), 'w') as fh:\n",
    "    for fn, cid in zip(kept_fn, kept_label):\n",
    "        classes[cid] += 1\n",
    "        fh.write('{} {}\\n'.format(fn, cid))\n",
    "        \n",
    "# see how many images are kept, per-class, after the duplication removal\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([50000,   500,   500,   500,   500,   500,   500,   500,   500,\n",
       "         500], dtype=int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_classes = np.zeros((10), dtype=np.int32)\n",
    "for cid in list_label:\n",
    "    total_classes[cid] += 1\n",
    "total_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, you will have two annotation files, `train_kept_{}_naive.txt` and `train_kept_{}_hash.txt`.\n",
    "Move the two files to your dataset directory to train classifiers and compare performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
